[runtime]
sampler = polychord
root = ${PWD}
verbosity = standard

[test]
save_dir=output/planck_class
fatal_errors=T


[DEFAULT]
; This value is used below as %(planck_path)s
planck_path = likelihood/planck2018/baseline/plc_3.0


[pipeline]
; these names refer to sections later in the file:
modules = consistency class planck
values = examples/planck_values.ini
priors = examples/planck_priors.ini
debug=T
timing=F


[planck]
;Planck 2018 high ell TT,TE and EE + low ell TT + low ell EE (in Planck notations = TT+lowE)
;without CMB lensing
file = likelihood/planck2018/planck_interface.so
; It would be nice to use the same likelihood files as the main planck (camb) test here,
; but the planck 2018 likelihood cannot cope with using the same file again in the same process,
; so when I run the automatic test program it crashes.
; This is not encouraging.
; data_1 = %(planck_path)s/hi_l/plik/plik_rd12_HM_v22b_TTTEEE.clik
data_1 = %(planck_path)s/low_l/commander/commander_dx12_v3_2_29.clik
data_2 = %(planck_path)s/low_l/simall/simall_100x143_offlike5_EE_Aplanck_B.clik


; The consistency module translates between our chosen parameterization
; and any other that modules in the pipeline may want (e.g. camb)
[consistency]
file = ./utility/consistency/consistency_interface.py
cosmomc_theta = T

[class]
file = boltzmann/class/class_interface.py
version = 3.2.0
lmax = 2850
debug = T
zmax = 4.0
cmb = T
mpk = F
lensing = T
#class_non_linear = halofit

[polychord]
base_dir = chain_checkpoints
polychord_outfile_root=output
resume=T
feedback = 3
fast_fraction = 0.1
compression_factor = 0.00001
;Minimum settings for a "good enough" quick test
live_points = 250
num_repeats = 30
tolerance = 0.1
;Settings for high quality paper runs
; live_points = 500
; num_repeats=60
; tolerance=0.01
; boost_posteriors=10.0

[output]
filename= chain_output.txt
format=text
lock=F
privacy=F
